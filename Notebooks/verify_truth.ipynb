{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sqlite, PostgreSQL and parquet versions of truth tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Owner: **Joanne Bogart [@jrbogart](https://github.com/LSSTDESC/DC2-analysis/issues/new?body=@jrbogart)**  \n",
    "Last Verified to Run: \n",
    "\n",
    "This notebook makes various comparisons between different manifestations (sqlite, parquet, PostgreSQL) of the \"same\" truth table\n",
    "\n",
    "__Logistics__: This notebook is intended to be run through the JupyterHub NERSC interface available here: https://jupyter.nersc.gov. To setup your NERSC environment, please follow the instructions available here: \n",
    "https://confluence.slac.stanford.edu/display/LSSTDESC/Using+Jupyter+at+NERSC\n",
    "### Prerequisites\n",
    "* For access to PostgreSQL see [Getting Started with PostgreSQL at NERSC](https://confluence.slac.stanford.edu/x/s4joE), especially the \"Preliminaries\" section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa                 # maybe not necessary\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catalog:\n",
    "    \"\"\"\n",
    "    Store information needed to access a catalog in each of the three formats\n",
    "    \"\"\"\n",
    "    _sqlite_root = None\n",
    "    _pq_root = None\n",
    "    _pg_conn = None\n",
    "    Summary = 1\n",
    "    Variability = 2\n",
    "    Auxiliary = 3\n",
    "    \n",
    "    def set_sqlite_root(r):\n",
    "        Catalog._sqlite_root = r\n",
    "        \n",
    "    def set_parquet_root(r):\n",
    "        Catalog._parquet_root = r\n",
    "        \n",
    "    def set_pg_connection(c):\n",
    "        Catalog._pg_conn = c\n",
    "        \n",
    "    def pg_connection():\n",
    "        return Catalog._pg_conn\n",
    "        \n",
    "    def __init__(self, pg_table, sqlite_path, sqlite_table, parquet_path, \n",
    "                 table_type=Summary, name=''):\n",
    "        self._pg_table = pg_table\n",
    "        self._sqlite_path = sqlite_path\n",
    "        self._sqlite_table = sqlite_table\n",
    "        self._parquet_path = parquet_path\n",
    "        self._table_type = table_type\n",
    "        self._name = name\n",
    "        if table_type < Catalog.Summary or table_type > Catalog.Auxiliary:\n",
    "            print(\"Unknown table type\")\n",
    "        \n",
    "    @property\n",
    "    def pg_table(self):\n",
    "        return self._pg_table\n",
    "    \n",
    "    @property \n",
    "    def sqlite_table(self):\n",
    "        return self._sqlite_table\n",
    "        \n",
    "    @property\n",
    "    def sqlite_abspath(self):\n",
    "        return os.path.join(Catalog._sqlite_root, self._sqlite_path)\n",
    "    \n",
    "    @property\n",
    "    def parquet_abspath(self):\n",
    "        return os.path.join(Catalog._parquet_root, self._parquet_path)\n",
    "    \n",
    "    @property \n",
    "    def table_type(self):\n",
    "        return self._table_type\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the PostgreSQL db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'desc_dc2_drp'\n",
    "dbuser = 'desc_dc2_drp_user'\n",
    "dbhost = 'nerscdb03.nersc.gov'\n",
    "dbconfig = {'dbname' : dbname, 'user' : dbuser, 'host' : dbhost}\n",
    "pg_conn = psycopg2.connect(**dbconfig)\n",
    "\n",
    "Catalog.set_pg_connection(pg_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Catalog.set_sqlite_root('/global/cfs/cdirs/lsst/shared/DC2-prod/Run3.1i/truth')\n",
    "Catalog.set_parquet_root('/global/cscratch1/sd/jrbogart/desc/truth/pq')\n",
    "pg_tables = ['agn_truth.truth_summary', 'agn_truth.agn_auxiliary_info',\n",
    "            'agn_truth.agn_variability_truth', 'lensed_host_truth.truth_summary',\n",
    "            'lensed_agn_truth.truth_summary',\n",
    "            'lensed_agn_truth.lensed_agn_variability_truth',\n",
    "            'lensed_sne_truth.truth_summary',\n",
    "            'lensed_sne_truth.lensed_sn_variability_truth']\n",
    "\n",
    "sqlite_paths = ['agntruth/agn_truth_cat.db', 'agntruth/agn_truth_cat.db',\n",
    "               'agntruth/agn_variability_truth_cat.db',\n",
    "               'lensed_hosttruth/lensed_host_truth_cat.db',\n",
    "               'lensed_agntruth/lensed_agn_truth_cat.db',\n",
    "               'lensed_agntruth/lensed_agn_variability_truth_cat.db',\n",
    "               'lensed_snetruth/lensed_sne_truth_cat.db',\n",
    "               'lensed_snetruth/lensed_sne_truth_cat.db']\n",
    "sqlite_tables = ['truth_summary', 'agn_auxiliary_info', 'agn_variability_truth',\n",
    "                'truth_summary', 'truth_summary','lensed_agn_variability_truth',\n",
    "                'truth_summary', 'lensed_sn_variability_truth']\n",
    "\n",
    "parquet_paths = ['agn_truth_summary.parquet', 'agn_auxiliary_info.parquet',\n",
    "                'agn_variability_truth.parquet', 'lensed_host_truth_summary.parquet',\n",
    "                'lensed_agn_truth_summary.parquet',\n",
    "                'lensed_agn_variability_truth.parquet',\n",
    "                'lensed_sne_truth_summary.parquet',\n",
    "                'lensed_sn_variability_truth.parquet']\n",
    "table_types = [Catalog.Summary, Catalog.Auxiliary, Catalog.Variability, Catalog.Summary,\n",
    "              Catalog.Summary, Catalog.Variability, Catalog.Summary, Catalog.Variability]\n",
    "names = ['agn summary', 'agn aux', 'agn variability', 'lensed host summary', 'lensed agn summary',\n",
    "        'lensed agn variability', 'lensed sn summary', 'lensed sn variability']\n",
    "n_tables = len(parquet_paths)\n",
    "catalogs = []\n",
    "for i in range(n_tables):\n",
    "    catalogs.append(Catalog(pg_tables[i], sqlite_paths[i], sqlite_tables[i],\n",
    "                           parquet_paths[i], table_types[i], names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pg_columns(catalog, select_list, alias_list=None, other=None):\n",
    "    '''\n",
    "    Returns data frame version of db select output.  \n",
    "    Works for PostgreSQL.  It seems sqlite cursors don't support \"with\"\n",
    "    '''\n",
    "    cols = ','.join(select_list)\n",
    "    q = f\"\"\"SELECT {cols} FROM {catalog.pg_table}\"\"\"\n",
    "    if other:\n",
    "        q = ''.join([q,' ',other])\n",
    "        \n",
    "    #print('Postgres query: ', q)\n",
    "    conn = Catalog.pg_connection()\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(q)\n",
    "        records = cursor.fetchall()\n",
    "\n",
    "    if alias_list:\n",
    "        return pd.DataFrame(records, columns=alias_list)\n",
    "    else:\n",
    "        return pd.DataFrame(records, columns=select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sqlite_columns(catalog, select_list, alias_list=None, other=None):\n",
    "    '''\n",
    "    Returns data frame version of db select output.  \n",
    "    '''\n",
    "    cols = ','.join(select_list)\n",
    "    q = f\"\"\"SELECT {cols} FROM {catalog.sqlite_table}\"\"\"\n",
    "    if other:\n",
    "        q = ''.join([q,' ',other])\n",
    "    conn = sqlite3.connect(catalog.sqlite_abspath)\n",
    "    cursor = conn.cursor()\n",
    "  \n",
    "    cursor.execute(q)\n",
    "    records = cursor.fetchall()\n",
    " \n",
    "    if alias_list:\n",
    "        return pd.DataFrame(records, columns=alias_list)\n",
    "    else:\n",
    "        return pd.DataFrame(records, columns=select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parquet_columns(catalog, column_list):\n",
    "    return(pq.read_table(catalog.parquet_abspath, column_list)).to_pandas()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard queries, to be applied to each representation should include\n",
    "* getting length of id column (all tables have an id column)\n",
    "* comparing values for a couple rows.  For sqlite and parquet, expect rows will be returned in the same order.  For PostgreSQL might have to match ids (for variability tables would have to match (id, obshistid) for uniqueness)\n",
    "* plotting ra, dec (summary tables)\n",
    "* for variability tables, plot a light curve\n",
    "* histogramming a column or two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare counts.  Fetching counts is fast for parquet but rather slow \n",
    "# for large tables in the databases.\n",
    "\n",
    "for i in range(n_tables):\n",
    "    pg_df = get_pg_columns(catalogs[i], ['count(id) as count_id'],\n",
    "                           alias_list=['count_id'])\n",
    "    print(f\"\\nFor catalog {catalogs[i].name}\\n     pg count={pg_df['count_id'][0]}\")    \n",
    "   \n",
    "    sq_df = get_sqlite_columns(catalogs[i], ['count(id) as count_id'],\n",
    "                               alias_list=['count_id'])\n",
    "    pq_df = get_parquet_columns(catalogs[i], ['id'])\n",
    "   \n",
    "    print(f\" sqlite count={sq_df['count_id'][0]}\")\n",
    "    print(f\"parquet count={len(pq_df['id'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Rows\n",
    "To find column names, can open parquet file.  Then pq_file.schema.column(i) returns information about the ith column.   Includes field `name` and `physical_type`\n",
    "\n",
    "For truth summary and auxiliary tables, id is unique.  For variability tables, use\n",
    "(id, obsHistID)   (the field is lowercase in the PostgreSQL db, but it shouldn't care if uppercase is passed in)\n",
    "\n",
    "To start just print out values for all columns for each format (excep not coord in Postgres since the others don't have it) for a row or two and compare visually. Later might want to check for within-tolerance for floating point fields and identity for the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot coverage\n",
    "For each table of type Catalog.Summary, plot (ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage(catalog):\n",
    "    # Get the data\n",
    "    columns = ['ra', 'dec']\n",
    "\n",
    "    if catalog.table_type != Catalog.Summary:\n",
    "        print('Only plot coverage for truth summary catalogs')\n",
    "        return\n",
    "    \n",
    "    pg_data = get_pg_columns(catalog, columns)\n",
    "    sq_data = get_sqlite_columns(catalog, columns)\n",
    "    parquet_data = get_parquet_columns(catalog, columns)\n",
    "    \n",
    "    # and plot\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.suptitle(f'{catalog.name} Coverage')\n",
    "    plt.subplot(131).set_title('PostgreSQL')\n",
    "    plt.xlabel('ra')\n",
    "    plt.ylabel('dec')\n",
    "    plt.scatter(np.array(pg_data['ra']), np.array(pg_data['dec']), s=0.6)\n",
    " \n",
    "    plt.subplot(132).set_title('SQLite')\n",
    "    plt.xlabel('ra')\n",
    "    plt.ylabel('dec')\n",
    "    plt.scatter(np.array(sq_data['ra']), np.array(sq_data['dec']), s=0.6)   \n",
    "    plt.subplot(133).set_title('Parquet')\n",
    "    plt.xlabel('ra')\n",
    "    plt.ylabel('dec')\n",
    "    plt.scatter(np.array(parquet_data['ra']), np.array(parquet_data['dec']), s=0.6)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_coverage(catalog, rtol=1e-5, atol=1e-8, verbose=False):\n",
    "    # Get the data\n",
    "    columns = ['ra', 'dec', 'id']\n",
    "\n",
    "    if catalog.table_type != Catalog.Summary:\n",
    "        print('Only plot coverage for truth summary catalogs')\n",
    "        return\n",
    "    \n",
    "    pg_data = get_pg_columns(catalog, columns).sort_values(by=['id'])\n",
    "    sq_data = get_sqlite_columns(catalog, columns).sort_values(by=['id'])\n",
    "    id_mask = (pg_data['id'] == sq_data['id'])\n",
    "\n",
    "    parquet_data = get_parquet_columns(catalog, columns).sort_values(by=['id'])\n",
    "\n",
    "    if verbose:\n",
    "        fmt = '{} first entry: id={}, ra={}, dec={}'\n",
    "        print(fmt.format('SQLite  ', sq_data['id'][0], sq_data['ra'][0], \n",
    "                         sq_data['dec'][0]))\n",
    "        print(fmt.format('Postgres', pg_data['id'][0], pg_data['ra'][0], \n",
    "                         pg_data['dec'][0]))\n",
    "        print(fmt.format('Parquet ', parquet_data['id'][0], parquet_data['ra'][0], \n",
    "                         parquet_data['dec'][0]))\n",
    "    print('\\nCatalog ', catalog.name)\n",
    "    ok = np.allclose(np.asarray(sq_data['ra']), np.asarray(pg_data['ra']),\n",
    "                     rtol=rtol, atol=atol)\n",
    "    ok = ok and np.allclose(np.asarray(sq_data['dec']), np.asarray(pg_data['dec']),\n",
    "                            rtol=rtol, atol=atol)\n",
    "    if ok:\n",
    "        print('SQLite and PostgreSQL datasets are sufficiently close')\n",
    "    else:\n",
    "        print('SQLite, PostgreSQL mismatch')\n",
    "        \n",
    "    ok = np.allclose(np.asarray(sq_data['ra']), np.asarray(parquet_data['ra']),\n",
    "                     rtol=rtol, atol=atol)\n",
    "    ok = ok and np.allclose(np.asarray(sq_data['dec']), np.asarray(parquet_data['dec']),\n",
    "                            rtol=rtol, atol=atol)\n",
    "    if ok:\n",
    "        print('SQLite and Parquet datasets are sufficiently close')\n",
    "    else:\n",
    "        print('SQLite, Parquet mismatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare ra, dec numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in catalogs:\n",
    "    if c.table_type == Catalog.Summary:\n",
    "        # Since ra, dec are double precision, make tolerances a little tighter than default\n",
    "        compare_coverage(c, rtol=1e-6, atol=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light curves\n",
    "Compare light curves for AGNs.  The same could be done for lensed agn and lensed SNe.\n",
    "\n",
    "First find delta flux readings for stars which are expected to be in the field of view for a particular visit. This sort of query returns practically instantly in PostgreSQL because in the `stellar_variability_truth` table both of the columns mentioned in the `WHERE` clause - `id` and `obshistid` - are indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cone_search(coord_column, ra, dec, radius):\n",
    "    '''\n",
    "    Parameters\n",
    "    coord_column:  name of column of type earth in the table\n",
    "    ra:  ra value at center of cone (degrees)\n",
    "    dec:  dec value at center of cone (degrees)\n",
    "    radius: radius of cone (arcseconds)\n",
    "    \n",
    "    Returns\n",
    "    Condition to be inserted into WHERE clause for the query\n",
    "    '''\n",
    "    cond = f\"\"\"conesearch({coord_column},'{ra}','{dec}','{radius}')\"\"\"\n",
    "    return cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a location that probably gets lots of visits\n",
    "ra = 53.0      \n",
    "dec = -28.1\n",
    "radius = 80   \n",
    "truth_schema = 'agn_truth'\n",
    "tbl_spec = f\"\"\"SELECT S.id, S.ra, S.dec, max(abs(V.delta_flux)) as max_delta_flux,count(V.bandpass) AS visit_count \n",
    "           FROM {truth_schema}.truth_summary AS S JOIN \n",
    "           {truth_schema}.agn_variability_truth AS V ON S.id=V.id \"\"\"\n",
    "where = \"WHERE \" + format_cone_search('S.coord', ra, dec, radius) + \" AND S.is_variable=1 \"\n",
    "group_by = \" GROUP BY S.id,S.ra,S.dec ORDER BY max_delta_flux DESC\"\n",
    "q = tbl_spec + where + group_by\n",
    "print(q)\n",
    "\n",
    "# This takes a couple minutes to complete\n",
    "dbconn = Catalog.pg_connection()\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(q)\n",
    "    records = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths = pd.DataFrame(records, columns=['id', 'ra','dec', 'max_delta_flux','visit_count'])\n",
    "df_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot light curves for one star\n",
    "Pick first object for large delta flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_id = df_lengths['id'][0]\n",
    "lc_ra = df_lengths['ra'][0]\n",
    "lc_dec = df_lengths['dec'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('id is: ', lc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data\n",
    "For each data source get delta_flux and time values for the plot and some summary information about the star. Order conveniently for plotting.\n",
    "\n",
    "This query runs quickly in PostgreSQL (the variability table is indexed by id),\n",
    "but the same query made on the SQLite and parquet files is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'agn variability'\n",
    "\n",
    "#PostgreSQL\n",
    "cat = None\n",
    "for c in catalogs:\n",
    "    if c.name == name:\n",
    "        print('Found catalog')\n",
    "        cat = c\n",
    "        break\n",
    "if cat:\n",
    "    cols = ['bandpass', 'MJD', 'delta_flux']\n",
    "    other = f\"WHERE id='{lc_id}' ORDER BY bandpass, MJD\"\n",
    "    pg_df = get_pg_columns(cat, cols, other=other)\n",
    "    print('PostgreSQL data shape: ', pg_df.shape)\n",
    "else:\n",
    "    print('No such catalog \"', name, '\"')\n",
    "    print('Fix before proceeding with remainder of notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite\n",
    "sq_df = get_sqlite_columns(cat, cols, other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SQLite data shape: ',sq_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parquet\n",
    "pq_cols = ['id', 'bandpass', 'MJD', 'delta_flux']\n",
    "pq_df_orig = get_parquet_columns(cat, pq_cols)\n",
    "print('Parquet data shape initially: ', pq_df_orig.shape)\n",
    "pq_df = pq_df_orig.query(f'id == \"{lc_id}\"')\n",
    "print('Parquet data shape after filtering: ', pq_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_df.sort_values(by=['bandpass', 'MJD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_band_lc(times, fluxes, params):\n",
    "    out = plt.scatter(np.asarray(times), np.asarray(fluxes), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_title(id, ra, dec, band=None, object='star'):  \n",
    "    if band is None:\n",
    "        return f'Per-band light curves for star {id} at (ra,dec)=({ra}, {dec})'\n",
    "    else:\n",
    "        return f'Light curve for {object} {id}, band={band} at (ra,dec)=({ra}, {dec})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_object(title, the_data, data_source, band):\n",
    "    '''\n",
    "    Plot requested band\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    title : string\n",
    "    the_data : list of data frame which must include columns filtername, obsstart, mag\n",
    "    data_source : list of data source names\n",
    "    band : Must be one of ['r', 'i','g', 'u', 'y', 'z']\n",
    "    '''\n",
    "    if band not in ['r', 'i','g', 'u', 'y', 'z']:\n",
    "        print('Unknown band \"',band,'\"')\n",
    "        return\n",
    "    color_dict  = {'r' : 'red', 'g' : 'green', 'i' : 'orange', 'u' : 'magenta',\n",
    "                  'y' : 'blue', 'z' : 'black'}\n",
    "    \n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.suptitle(title)\n",
    "    plt_shape_min = 100 + 10 * len(data_source) + 1\n",
    "    for i in range(len(data_source)):\n",
    "        plt.subplot(plt_shape_min + i).set_title(data_source[i])\n",
    "    \n",
    "        good_d = the_data[i][(np.isnan(the_data[i].delta_flux)==False)]\n",
    "        band_d = good_d[(good_d.bandpass==band)]\n",
    "        plt.xlabel('Julian date')\n",
    "        plt.ylabel('Delta flux')\n",
    "        params = {'marker' : 'o', 'label' : f'band {band}', 'color' : color_dict[band],\n",
    "                 's' : 1.0}\n",
    "\n",
    "        plot_band_lc(list(band_d['MJD']), list(band_d['delta_flux']),\n",
    "                    params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in ('i', 'r', 'g', 'u'):\n",
    "    title = format_title(lc_id, lc_ra, lc_dec, band, object='agn')\n",
    "    plot_object(title, [pg_df, sq_df, pq_df], ('PostgreSQL', 'SQLite', 'Parquet'), band)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "desc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
