{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sqlite, PostgreSQL and parquet versions of truth tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Owner: **Joanne Bogart [@jrbogart](https://github.com/LSSTDESC/DC2-analysis/issues/new?body=@jrbogart)**  \n",
    "Last Verified to Run: \n",
    "\n",
    "This notebook makes various comparisons between different manifestations (sqlite, parquet, PostgreSQL) of the \"same\" truth table\n",
    "\n",
    "__Logistics__: This notebook is intended to be run through the JupyterHub NERSC interface available here: https://jupyter.nersc.gov. To setup your NERSC environment, please follow the instructions available here: \n",
    "https://confluence.slac.stanford.edu/display/LSSTDESC/Using+Jupyter+at+NERSC\n",
    "### Prerequisites\n",
    "* For access to PostgreSQL see [Getting Started with PostgreSQL at NERSC](https://confluence.slac.stanford.edu/x/s4joE), especially the \"Preliminaries\" section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import psycopg2\n",
    "import sqlite3\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa                 # maybe not necessary\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catalog:\n",
    "    \"\"\"\n",
    "    Store information needed to access a catalog in each of the three formats\n",
    "    \"\"\"\n",
    "    _sqlite_root = None\n",
    "    _pq_root = None\n",
    "    _pg_conn = None\n",
    "    Summary = 1\n",
    "    Variability = 2\n",
    "    Auxiliary = 3\n",
    "    \n",
    "    def set_sqlite_root(r):\n",
    "        Catalog._sqlite_root = r\n",
    "        \n",
    "    def set_parquet_root(r):\n",
    "        Catalog._parquet_root = r\n",
    "        \n",
    "    def set_pg_connection(c):\n",
    "        Catalog._pg_conn = c\n",
    "        \n",
    "    def pg_connection():\n",
    "        return Catalog._pg_conn\n",
    "        \n",
    "    def __init__(self, pg_table, sqlite_path, sqlite_table, parquet_path, \n",
    "                 table_type=Summary, name=''):\n",
    "        self._pg_table = pg_table\n",
    "        self._sqlite_path = sqlite_path\n",
    "        self._sqlite_table = sqlite_table\n",
    "        self._parquet_path = parquet_path\n",
    "        self._table_type = table_type\n",
    "        self._name = name\n",
    "        if table_type < Catalog.Summary or table_type > Catalog.Auxiliary:\n",
    "            print(\"Unknown table type\")\n",
    "        \n",
    "    @property\n",
    "    def pg_table(self):\n",
    "        return self._pg_table\n",
    "    \n",
    "    @property \n",
    "    def sqlite_table(self):\n",
    "        return self._sqlite_table\n",
    "        \n",
    "    @property\n",
    "    def sqlite_abspath(self):\n",
    "        return os.path.join(Catalog._sqlite_root, self._sqlite_path)\n",
    "    \n",
    "    @property\n",
    "    def parquet_abspath(self):\n",
    "        return os.path.join(Catalog._parquet_root, self._parquet_path)\n",
    "    \n",
    "    @property \n",
    "    def table_type(self):\n",
    "        return self._table_type\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the PostgreSQL db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'desc_dc2_drp'\n",
    "dbuser = 'desc_dc2_drp_user'\n",
    "dbhost = 'nerscdb03.nersc.gov'\n",
    "dbconfig = {'dbname' : dbname, 'user' : dbuser, 'host' : dbhost}\n",
    "pg_conn = psycopg2.connect(**dbconfig)\n",
    "\n",
    "Catalog.set_pg_connection(pg_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Catalog.set_sqlite_root('/global/cfs/cdirs/lsst/shared/DC2-prod/Run3.1i/truth')\n",
    "Catalog.set_parquet_root('/global/cscratch1/sd/jrbogart/desc/truth/pq')\n",
    "pg_tables = ['agn_truth.truth_summary', 'agn_truth.agn_auxiliary_info',\n",
    "            'agn_truth.agn_variability_truth', 'lensed_host_truth.truth_summary',\n",
    "            'lensed_agn_truth.truth_summary',\n",
    "            'lensed_agn_truth.lensed_agn_variability_truth',\n",
    "            'lensed_sne_truth.truth_summary',\n",
    "            'lensed_sne_truth.lensed_sn_variability_truth']\n",
    "\n",
    "sqlite_paths = ['agntruth/agn_truth_cat.db', 'agntruth/agn_truth_cat.db',\n",
    "               'agntruth/agn_variability_truth_cat.db',\n",
    "               'lensed_hosttruth/lensed_host_truth_cat.db',\n",
    "               'lensed_agntruth/lensed_agn_truth_cat.db',\n",
    "               'lensed_agntruth/lensed_agn_variability_truth_cat.db',\n",
    "               'lensed_snetruth/lensed_sne_truth_cat.db',\n",
    "               'lensed_snetruth/lensed_sne_truth_cat.db']\n",
    "sqlite_tables = ['truth_summary', 'agn_auxiliary_info', 'agn_variability_truth',\n",
    "                'truth_summary', 'truth_summary','lensed_agn_variability_truth',\n",
    "                'truth_summary', 'lensed_sn_variability_truth']\n",
    "\n",
    "parquet_paths = ['agn_truth_summary.parquet', 'agn_auxiliary_info.parquet',\n",
    "                'agn_variability_truth.parquet', 'lensed_host_truth_summary.parquet',\n",
    "                'lensed_agn_truth_summary.parquet',\n",
    "                'lensed_agn_variability_truth.parquet',\n",
    "                'lensed_sne_truth_summary.parquet',\n",
    "                'lensed_sn_variability_truth.parquet']\n",
    "table_types = [Catalog.Summary, Catalog.Auxiliary, Catalog.Variability, Catalog.Summary,\n",
    "              Catalog.Summary, Catalog.Variability, Catalog.Summary, Catalog.Variability]\n",
    "names = ['agn summary', 'agn aux', 'agn variabity', 'lensed host summary', 'lensed agn summary',\n",
    "        'lensed agn variability', 'lensed sn summary', 'lensed sn variability']\n",
    "n_tables = len(parquet_paths)\n",
    "catalogs = []\n",
    "for i in range(n_tables):\n",
    "    catalogs.append(Catalog(pg_tables[i], sqlite_paths[i], sqlite_tables[i],\n",
    "                           parquet_paths[i], table_types[i], names[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenience utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_pg_columns(conn, catalog, select_list, alias_list=None, where=None):\n",
    "def get_pg_columns(catalog, select_list, alias_list=None, where=None):\n",
    "    '''\n",
    "    Returns data frame version of db select output.  \n",
    "    Works for PostgreSQL.  It seems sqlite cursors don't support \"with\"\n",
    "    '''\n",
    "    cols = ','.join(select_list)\n",
    "    q = f\"\"\"SELECT {cols} FROM {catalog.pg_table}\"\"\"\n",
    "    if where:\n",
    "        q = ''.join([q,' WHERE ',where])\n",
    "    conn = Catalog.pg_connection()\n",
    "\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(q)\n",
    "        records = cursor.fetchall()\n",
    "    if alias_list:\n",
    "        return pd.DataFrame(records, columns=alias_list)\n",
    "    else:\n",
    "        return pd.DataFrame(records, columns=select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sqlite_columns(catalog, select_list, alias_list=None, where=None):\n",
    "    '''\n",
    "    Returns data frame version of db select output.  \n",
    "    '''\n",
    "    cols = ','.join(select_list)\n",
    "    q = f\"\"\"SELECT {cols} FROM {catalog.sqlite_table}\"\"\"\n",
    "    if where:\n",
    "        q = ''.join([q,' WHERE ',where])\n",
    "    conn = sqlite3.connect(catalog.sqlite_abspath)\n",
    "    cursor = conn.cursor()\n",
    "  \n",
    "    cursor.execute(q)\n",
    "    records = cursor.fetchall()\n",
    "    if alias_list:\n",
    "        return pd.DataFrame(records, columns=alias_list)\n",
    "    else:\n",
    "        return pd.DataFrame(records, columns=select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parquet_columns(catalog, column_list):\n",
    "    return(pq.read_table(catalog.parquet_abspath, column_list)).to_pandas()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard queries, to be applied to each representation should include\n",
    "* getting length of id column (all tables have an id column)\n",
    "* comparing values for a couple rows.  For sqlite and parquet, expect rows will be returned in the same order.  For PostgreSQL might have to match ids (for variability tables would have to match (id, obshistid) for uniqueness)\n",
    "* plotting ra, dec (summary tables)\n",
    "* for variability tables, plot a light curve\n",
    "* histogramming a column or two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare counts\n",
    "\n",
    "for i in range(n_tables):\n",
    "    pg_df = get_pg_columns(catalogs[i], ['count(id) as count_id'],\n",
    "                           alias_list=['count_id'])\n",
    "    print(f\"\\nFor catalog {catalogs[i].name}\\n     pg count={pg_df['count_id'][0]}\")    \n",
    "   \n",
    "    sq_df = get_sqlite_columns(catalogs[i], ['count(id) as count_id'],\n",
    "                               alias_list=['count_id'])\n",
    "    pq_df = get_parquet_columns(catalogs[i], ['id'])\n",
    "   \n",
    "    print(f\" sqlite count={sq_df['count_id'][0]}\")\n",
    "    print(f\"parquet count={len(pq_df['id'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Rows\n",
    "To find column names, can open parquet file.  Then pq_file.schema.column(i) returns information about the ith column.   Includes field `name` and `physical_type`\n",
    "\n",
    "For truth summary and auxiliary tables, id is unique.  For variability tables, use\n",
    "(id, obsHistID)   (the field is lowercase in the PostgreSQL db, but it shouldn't care if uppercase is passed in)\n",
    "\n",
    "To start just print out values for all columns for each format (excep not coord in Postgres since the others don't have it) for a row or two and compare visually. Later might want to check for within-tolerance for floating point fields and identity for the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot coverage\n",
    "For each table of type Catalog.Summary, plot (ra, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage(catalog):\n",
    "    # Get the data\n",
    "    columns = ['ra', 'dec']\n",
    "\n",
    "    if catalog.table_type != Catalog.Summary:\n",
    "        print('Only plot coverage for truth summary catalogs')\n",
    "        return\n",
    "    \n",
    "    pg_data = get_pg_columns(catalog, columns)\n",
    "    sq_data = get_sqlite_columns(catalog, columns)\n",
    "    parquet_data = get_parquet_columns(catalog, columns)\n",
    "    \n",
    "    # and plot\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.suptitle(f'{catalog.name} Coverage')\n",
    "    plt.subplot(131).set_title('PostgreSQL')\n",
    "    plt.xlabel('ra')\n",
    "    plt.ylabel('dec')\n",
    "    plt.scatter(np.array(pg_data['ra']), np.array(pg_data['dec']), s=0.6)\n",
    " \n",
    "    plt.subplot(132).set_title('SQLite')\n",
    "    plt.xlabel('ra')\n",
    "    plt.ylabel('dec')\n",
    "    plt.scatter(np.array(sq_data['ra']), np.array(sq_data['dec']), s=0.6)   \n",
    "    plt.subplot(133).set_title('Parquet')\n",
    "    plt.xlabel('ra')\n",
    "    plt.ylabel('dec')\n",
    "    plt.scatter(np.array(parquet_data['ra']), np.array(parquet_data['dec']), s=0.6)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coverage(catalogs[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram a column\n",
    "Find delta flux readings for stars which are expected to be in the field of view for a particular visit. This sort of query returns practically instantly. In the `stellar_variability_truth` both of the columns mentioned in the `WHERE` clause - `id` and `obshistid` - are indexed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light curves\n",
    "Find a reasonable candidate (maybe one each agn, lensed agn, lensed sn?) and compare light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cone_search(coord_column, ra, dec, radius):\n",
    "    '''\n",
    "    Parameters\n",
    "    coord_column:  name of column of type earth in the table\n",
    "    ra:  ra value at center of cone (degrees)\n",
    "    dec:  dec value at center of cone (degrees)\n",
    "    radius: radius of cone (arcseconds)\n",
    "    \n",
    "    Returns\n",
    "    Condition to be inserted into WHERE clause for the query\n",
    "    '''\n",
    "    cond = f\"\"\"conesearch({coord_column},'{ra}','{dec}','{radius}')\"\"\"\n",
    "    return cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a location that probably gets lots of visits\n",
    "# for (53.0, -28.1, 80)  get \n",
    "ra = 53.0      \n",
    "dec = -28.1\n",
    "radius = 80   \n",
    "truth_schema = 'agn_truth'\n",
    "tbl_spec = f\"\"\"SELECT S.id, S.ra, S.dec, max(abs(V.delta_flux)),count(V.bandpass) AS visit_count \n",
    "           FROM {truth_schema}.truth_summary AS S JOIN \n",
    "           {truth_schema}.agn_variability_truth AS V ON S.id=V.id \"\"\"\n",
    "where = \"WHERE \" + format_cone_search('S.coord', ra, dec, radius) + \" AND S.is_variable=1 \"\n",
    "group_by = \" GROUP BY S.id,S.ra,S.dec\"\n",
    "q = tbl_spec + where + group_by\n",
    "print(q)\n",
    "\n",
    "# This takes a couple minutes to complete\n",
    "dbconn = Catalog.pg_connection()\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(q)\n",
    "    records = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths = pd.DataFrame(records, columns=['id', 'ra','dec', 'max_delta_flux','count'])\n",
    "df_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, but this time don't count visits. Get the delta_flux values instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = ['S.id', 'ra', 'dec', 'bandpass', 'delta_flux']\n",
    "col_list = (',').join(columns)\n",
    "tbl_spec = f\"\"\"SELECT {col_list} \n",
    "           FROM {truth_schema}.truth_summary AS S JOIN \n",
    "           {truth_schema}.agn_variability_truth AS V ON S.id=V.id \"\"\"\n",
    "where = \"WHERE \" + format_cone_search('S.coord', ra, dec, radius) + \" and S.is_variable=1 \"\n",
    "q = tbl_spec + where\n",
    "print(q)\n",
    "\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(q)\n",
    "    records_lc = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cone_lcs = pd.DataFrame(records_lc, columns=columns)\n",
    "df_cone_lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot light curves for one star\n",
    "Pick the fourth object from the results of the first query in this section (id=2643077650549) since max_delta_flux is large\n",
    "#### Get the data\n",
    "Get delta_flux and time values for the plot and some summary information about the star. Use `ORDER BY` clause so that data are presented conveniently for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 2643077650549\n",
    "var_tbl = 'agn_variability_truth'\n",
    "lc_q = f\"\"\"SELECT bandpass,mjd,delta_flux FROM {truth_schema}.{var_tbl}\n",
    "       WHERE id='{id}' ORDER BY bandpass, mjd;\"\"\"\n",
    "print(lc_q)\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(lc_q)\n",
    "    lc_records = cursor.fetchall()\n",
    "print(len(lc_records))\n",
    "df_single_lc = pd.DataFrame(lc_records, columns=['bandpass','mjd','delta_flux'])\n",
    "df_single_lc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save ra, dec for the object into variables to be used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_tbl = 'truth_summary'\n",
    "sum_q = f\"\"\"SELECT ra,dec FROM {truth_schema}.{sum_tbl} \n",
    "         WHERE id='{id}';\"\"\"\n",
    "print(sum_q)\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(sum_q)\n",
    "    sum_record = cursor.fetchone()\n",
    "lc_ra = sum_record[0]\n",
    "lc_dec = sum_record[1]\n",
    "print(f'ra={lc_ra}, dec={lc_dec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "def plot_band_lc(axes, times, fluxes, params):\n",
    "    out = axes.scatter(np.asarray(times), np.asarray(fluxes), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_level(axes, yvalue, params):\n",
    "    xmin, xmax = axes.get_xlim()\n",
    "    out = axes.plot(np.asarray([xmin, xmax]), np.asarray([yvalue, yvalue]), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_title(id, ra, dec, band=None, object='star'):  \n",
    "    if band is None:\n",
    "        return f'Per-band light curves for star {id} at (ra,dec)=({ra}, {dec})'\n",
    "    else:\n",
    "        return f'Light curve for {object} {id}, band={band} at (ra,dec)=({ra}, {dec})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_object(title, the_data, band=None):\n",
    "    '''\n",
    "    Plot r, g and i light 'curves' (delta_flux as scatter plot) for an object\n",
    "    or plot only requested band\n",
    "    Parameters\n",
    "    -----------\n",
    "    title : string\n",
    "    the_data : data frame which must include columns filtername, obsstart, mag\n",
    "    '''\n",
    "    good_d = the_data[(np.isnan(the_data.delta_flux)==False)]\n",
    "    red_d = good_d[(good_d.bandpass==\"r\")]\n",
    "    green_d = good_d[(good_d.bandpass==\"g\")]\n",
    "    i_d = good_d[(good_d.bandpass==\"i\")]\n",
    "    #print(\"red data shape: \", red_e.shape, \"   green data shape: \", green_e.shape, \"  i data shape: \", i_e.shape)\n",
    "    fix, axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Julian date')\n",
    "    plt.ylabel('Delta flux')\n",
    "\n",
    "    params_r = {'marker' : 'o', 'label' : 'r band', 'color' : 'red'}\n",
    "    params_g = {'marker' : 'o', 'label' : 'g band', 'color' : 'green'}\n",
    "    params_i = {'marker' : 'o', 'label' : 'i band', 'color' : 'orange'}\n",
    "    #print('In plot_object printing i-band values')\n",
    "    #for ival in list(i_d['mag']): print(ival)\n",
    "    if band is None or band=='r':\n",
    "        plot_band_lc(axes, list(red_d['mjd']), list(red_d['delta_flux']), params_r)\n",
    "    if band is None or band=='g':\n",
    "        plot_band_lc(axes, list(green_d['mjd']), list(green_d['delta_flux']), params_g)\n",
    "    if band is None or band=='i':\n",
    "        plot_band_lc(axes, list(i_d['mjd']), list(i_d['delta_flux']), params_i)\n",
    "    #plot_level(axes, coadd_mag['r'], {'label' : 'r coadd mag', 'color' : 'red'})\n",
    "    #plot_level(axes, coadd_mag['g'], {'label' : 'g coadd mag', 'color' : 'green'})\n",
    "    #plot_level(axes, coadd_mag['i'], {'label' : 'i coadd mag', 'color' : 'orange'})\n",
    "    if band is None:\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in ('r','g','i'):\n",
    "    title = format_title(id, lc_ra, lc_dec, band, object='agn')\n",
    "    plot_object(title, df_single_lc, band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do it again for sqlite data and parquet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is it in the object table?\n",
    "First get truth information for our chosen star, then try to find a match, restricting to point sources within a few arcseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_q = f\"SELECT ra,dec,flux_g,flux_r,flux_i from {truth_schema}.truth_summary where id='{id}'\"\n",
    "print(truth_q)\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(truth_q)\n",
    "    truth_records = cursor.fetchall()\n",
    "#truth_records\n",
    "print(len(truth_records))\n",
    "truth_df = None\n",
    "truth_df = pd.DataFrame(truth_records, columns=['ra', 'dec', 'flux_g', 'flux_r', 'flux_i'])\n",
    "truth_df.shape\n",
    "truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "desc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
